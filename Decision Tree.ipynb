{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decision Tree Regression",
   "id": "8c88fc62fc4c5c3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T05:16:54.159830Z",
     "start_time": "2025-11-05T05:16:53.749725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 其他库已在 sample.ipynb导入了 例如：\n",
    "# import numpy as np\n",
    "# from sklearn import metrics\n",
    "# import matplotlib.pyplot as plt"
   ],
   "id": "a3eabaebf7bd11a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.1 基准（未剪枝）决策树模型\n",
    "首先，我们训练一个使用默认参数的决策树。未剪枝的树会尽可能生长，导致在训练集上表现完美，但在测试集上表现不佳（即过度拟合）。"
   ],
   "id": "3df7605671313276"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. 初始化模型\n",
    "# 使用 random_state=0 确保结果可复现\n",
    "dt_baseline = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# 2. 训练模型\n",
    "dt_baseline.fit(X_train, y_train)\n",
    "\n",
    "# 3. 评估模型\n",
    "y_pred_dt_baseline = dt_baseline.predict(X_test)\n",
    "\n",
    "print(\"---The baseline decision tree model (unpruned)---\")\n",
    "print(f'R2 Score: {metrics.r2_score(y_test, y_pred_dt_baseline):.4f}')\n",
    "print(f'MAE: {metrics.mean_absolute_error(y_test, y_pred_dt_baseline):.4f}')\n",
    "# sample.ipynb 中使用了 RMSE\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred_dt_baseline)):.4f}')\n",
    "\n",
    "# 检查树的深度\n",
    "print(f'\\nMaximum depth of decision tree: {dt_baseline.get_depth()}')"
   ],
   "id": "a37234d36359b753"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.2 使用 GridSearchCV 优化决策树（剪枝）\n",
    "基准模型很可能过度拟合（测试集 R² 较低，RMSE 较高）。现在我们使用 GridSearchCV来搜索最佳的“剪枝”超参数，以提高模型的泛化能力。\n",
    "\n",
    "我们将调整 max_depth（最大深度）和 min_samples_leaf（叶节点最小样本数）。"
   ],
   "id": "7956801f2f2f30d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. 定义参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],          # Try different tree depths\n",
    "    'min_samples_leaf': [5, 10, 20, 30],      # Minimum number of samples required for leaf nodes\n",
    "    'min_samples_split': [10, 20, 40]     # Minimum number of samples required for internal node splitting\n",
    "}\n",
    "\n",
    "# 2. 初始化 GridSearchCV\n",
    "# 我们使用 'r2' 作为评分标准\n",
    "# cv=5 表示5折交叉验证\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1, # 使用所有可用的CPU\n",
    "    verbose=1  # 显示搜索过程\n",
    ")\n",
    "\n",
    "# 3. 在训练数据上运行网格搜索\n",
    "print(\"Start searching for optimal parameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 打印最佳参数\n",
    "print(\"\\nSearch complete.\")\n",
    "print(\"Find the optimal parameter combination：\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 5. 获取最佳模型\n",
    "# grid_search.best_estimator_ 是使用最佳参数在 *整个* X_train 上自动重新训练好的模型\n",
    "dt_optimized = grid_search.best_estimator_"
   ],
   "id": "2dee99e6f827f979"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.3 评估优化后的决策树\n",
    "现在我们使用 grid_search 找到的最佳模型（dt_optimized）来评估其在测试集上的真实表现。\n"
   ],
   "id": "d5702b253e6f2f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. 使用优化后的模型进行预测\n",
    "y_pred_dt_optimized = dt_optimized.predict(X_test)\n",
    "\n",
    "print(\"--- 3.3 Evaluation of the optimized decision tree (after pruning) ---\")\n",
    "print(f'R2 Score: {metrics.r2_score(y_test, y_pred_dt_optimized):.4f}')\n",
    "print(f'MAE: {metrics.mean_absolute_error(y_test, y_pred_dt_optimized):.4f}')\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred_dt_optimized)):.4f}')\n",
    "\n",
    "print(f'\\nMaximum depth of the optimized tree： {dt_optimized.get_depth()}')"
   ],
   "id": "b0e34803f3aad11e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.4 商业洞察：特征重要性 (Feature Importance)\n",
    "决策树模型可以告诉我们哪些特征对预测“保险费用”最重要。这对于小组作业要求的商业解读至关重要。"
   ],
   "id": "fe02d406be59f008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. 获取特征重要性\n",
    "importances = dt_optimized.feature_importances_\n",
    "\n",
    "# 2. 获取特征名称\n",
    "# 确保 X_train 在此单元格中是 DataFrame 格式\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 3. 创建一个 DataFrame 便于查看\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. 打印重要的特征\n",
    "print(\"--- Feature Importance Ranking ---\")\n",
    "print(importance_df)\n",
    "\n",
    "# 5. 可视化特征重要性\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Optimized Decision Tree - Feature Importance')\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.gca().invert_yaxis() # 将最重要的特征放在顶部\n",
    "plt.show()"
   ],
   "id": "6a7921617af35806"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.5 商业洞察：可视化决策树\n",
    "为了更好地理解模型是如何做出决策的，我们可以（部分）可视化这棵优化后的树。参考 T5 Decision Tree 的方法，我们只绘制顶部几层（例如 max_depth=3），以保持可读性。"
   ],
   "id": "2f3d4dd9390e4b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20, 12)) # 调大图像尺寸以便看清\n",
    "\n",
    "# 使用 plot_tree 可视化\n",
    "# 我们只显示前3层 (max_depth=3)，以保持清晰\n",
    "plot_tree(\n",
    "    dt_optimized,\n",
    "    feature_names=feature_names,\n",
    "    filled=True,           # 用颜色填充节点\n",
    "    rounded=True,          # 圆角矩形框\n",
    "    fontsize=10,           # 字体大小\n",
    "    max_depth=3            # !! 仅用于可视化的深度\n",
    ")\n",
    "\n",
    "plt.title(f'Optimized Decision Tree (Visualized up to 3 levels, actual depth: {dt_optimized.get_depth()})')\n",
    "plt.show()"
   ],
   "id": "bfd7b151c7d9f4df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
